{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2640b842-1df8-4c0e-9a15-281d2dd07ed5",
   "metadata": {},
   "source": [
    "*bucket2 file takes train/test/val into account*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2264a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T14:34:36.063939Z",
     "start_time": "2023-03-07T14:34:36.059876Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import storage\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7693cf7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T14:34:37.590823Z",
     "start_time": "2023-03-07T14:34:36.671333Z"
    }
   },
   "outputs": [],
   "source": [
    "client = storage.Client(project='prime-basis-374911')\n",
    "bucket = client.get_bucket('kitchen-ai-images')\n",
    "\n",
    "#blob = bucket.get_blob('BROCCOLI_0.jpg')\n",
    "#img = Image.open(BytesIO(blob.download_as_bytes()))\n",
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f755944a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:55:35.916137Z",
     "start_time": "2023-03-07T15:55:35.910651Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_dataset = os.path.join(\"..\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d3494c-2c7c-429c-af93-5ebbb7a88e5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:22:43.645593Z",
     "start_time": "2023-03-07T16:22:38.659667Z"
    }
   },
   "outputs": [],
   "source": [
    "#ideas include updating to allow for getting specific class\n",
    "#or stopping at specific class\n",
    "#or loading n of each class\n",
    "#set classes to ignore\n",
    "\n",
    "##SKIPPED MUSHROOM 21\n",
    "#filenames_to_skip = [\"mushroom_21.jpg\"]\n",
    "\n",
    "#set to empty list just after, used for jumping in after image error\n",
    "classes_to_skip = [\n",
    "'asparagus',\n",
    "'beetroot',\n",
    "'broccoli',\n",
    "'cabbage',\n",
    "'capsicum',\n",
    "'carrot',\n",
    "'cauliflower',\n",
    "'celery',\n",
    "'corn',\n",
    "'cucumber',\n",
    "'eggplant',\n",
    "'garlic',\n",
    "'ginger',\n",
    "'leek',\n",
    "'lettuce']\n",
    "classes_to_skip = []\n",
    "\n",
    "\n",
    "\n",
    "mini_set_stop_class = \"capsicum\"\n",
    "\n",
    "#used to correctly index incoming data from 2 sets\n",
    "multi_set_input_class = [\"spinach\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c57562-3dd4-4b14-942e-e36377b0177d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:22:43.645593Z",
     "start_time": "2023-03-07T16:22:38.659667Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_bucket_data_to(miniset=False):\n",
    "    all_files = bucket.list_blobs()\n",
    "    \n",
    "    #set path to dataset\n",
    "    # if miniset:\n",
    "    #     path_to_dataset = os.path.join(\"..\", \"test_data\", \"0_test_miniset\")\n",
    "    # else:\n",
    "    #     path_to_dataset = os.path.join(\"..\", \"data\")\n",
    "    \n",
    "    #path_to_dataset = os.path.join(\"..\", \"test_data\", \"1_test_split_set\", \"test\")\n",
    "    \n",
    "    path_to_data_folder = os.path.join(\"..\", \"test_data\", \"3_test_from_bucket2\")\n",
    "    \n",
    "    #class_limit = 50\n",
    "    class_count = 0\n",
    "    train_count = 0\n",
    "    test_count = 0\n",
    "    val_count = 0\n",
    "    \n",
    "    current_class = \"\"\n",
    "    #this_file = next(all_files)\n",
    "    #for i in range(10):\n",
    "    \n",
    "    for this_file in all_files:\n",
    "        und_split = this_file.name.split('_')\n",
    "        dot_split = this_file.name.split('.')\n",
    "        food_bucket_path = this_file.path #to track old names\n",
    "\n",
    "        #get info from bucket path name\n",
    "        food_class = und_split[0].lower()\n",
    "        file_ext = dot_split[1] #print(img_ext)\n",
    "        file_num = dot_split[0].split('_')[-1] #print(file_num)\n",
    "        \n",
    "        #data_split = \"train\" \"test\" \"val\"\n",
    "        data_split = dot_split[0].split('_')[-2]      \n",
    "        \n",
    "        #create path to correct folder\n",
    "        path_to_dataset = os.path.join(path_to_data_folder, data_split)\n",
    "        \n",
    "        #create new file path\n",
    "        new_filename = food_class + \"_\" + file_num  + \".jpg\" #\".\" + file_ext\n",
    "        new_dir_path = os.path.join(path_to_dataset, food_class) #used to create folder if not already existing\n",
    "        new_path = os.path.join(new_dir_path,new_filename)   #class/class-n.ext\n",
    "        \n",
    "        #tracking\n",
    "        if food_class != current_class:\n",
    "            #if statement avoids printing empty for first\n",
    "            if current_class:\n",
    "                print(f\"loaded total {class_count} of {current_class}\")\n",
    "                print(f\"{train_count} train\")\n",
    "                print(f\"{val_count} val\")\n",
    "                print(f\"{test_count} test\")\n",
    "                    \n",
    "            current_class = food_class\n",
    "            class_count = 0\n",
    "            train_count, test_count, val_count = 0,0,0\n",
    "        \n",
    "        ## STOPPING / SKIPPING CONDITIONS\n",
    "        \n",
    "        #STOP AT GARLIC FOR MINISET\n",
    "        #if miniset and (food_class == mini_set_stop_class):\n",
    "        #    break\n",
    "        \n",
    "        if food_class in classes_to_skip:\n",
    "            continue\n",
    "        #if new_filename in filenames_to_skip:\n",
    "        #    continue\n",
    "        #if class_count > class_limit:\n",
    "        #    continue\n",
    "            \n",
    "        try:\n",
    "            #get image from bucket\n",
    "            file_image = Image.open(BytesIO(this_file.download_as_bytes()))\n",
    "            #convert to rgb ==> jpg\n",
    "            rgb_image = file_image.convert('RGB')\n",
    "\n",
    "            #save image\n",
    "            os.makedirs(new_dir_path, exist_ok=True) #True means don't create new dir if already exists #os.makedirs(path, exist_ok=True)\n",
    "            test_img = rgb_image.save(new_path)\n",
    "            \n",
    "            class_count += 1\n",
    "            \n",
    "            if data_split == \"train\":\n",
    "                train_count += 1\n",
    "            if data_split == \"test\":\n",
    "                test_count += 1\n",
    "            if data_split == \"validation\":\n",
    "                val_count += 1\n",
    "            \n",
    "        except:\n",
    "            print(f\"error loading from {food_bucket_path} \\n to {new_path}\")\n",
    "    \n",
    "    print(f\"Done! loaded {len(all_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c37e57bb-1b6a-4ddd-84b0-7d20da326bb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:22:43.645593Z",
     "start_time": "2023-03-07T16:22:38.659667Z"
    }
   },
   "outputs": [],
   "source": [
    "#save_bucket_data_to()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72bf5a37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:29:44.622805Z",
     "start_time": "2023-03-07T15:29:44.598577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 0 of \n",
      "loaded 1400 of broccoli\n",
      "loaded 1400 of cabbage\n",
      "loaded 1400 of carrot\n",
      "loaded 1400 of cauliflower\n",
      "loaded 1400 of cucumber\n",
      "loaded 1400 of potato\n",
      "loaded 1400 of pumpkin\n"
     ]
    }
   ],
   "source": [
    "save_bucket_data_to()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac6bc1-768c-4f45-8de1-587e25953e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
